{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp7goHcBAreg"
      },
      "source": [
        "# Cardiometabolic Risk: SSL Pretraining on Colab\n",
        "\n",
        "**Phase 5**: Train a self-supervised PPG encoder on 4,133 signals using Colab T4 GPU\n",
        "\n",
        "**Expected runtime**: 8â€“12 hours (50 epochs)  \n",
        "**Output**: Pretrained encoder checkpoint + training metrics\n",
        "\n",
        "**Prerequisites**:\n",
        "- Data uploaded to Google Drive: `/MyDrive/cardiometabolic-risk-colab/data/processed/`\n",
        "- GitHub repo exists and is public\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw7GxrO2Arei"
      },
      "source": [
        "## Setup: Mount Drive & Clone Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OerVxeV2Arej",
        "outputId": "237faba4-5d62-41c3-ff66-3411fb5637cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Drive mounted: True\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "COLAB_DRIVE_PATH = Path('/content/drive/MyDrive/cardiometabolic-risk-colab')\n",
        "print(f\"âœ… Drive mounted: {COLAB_DRIVE_PATH.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouwzKex7Arek",
        "outputId": "81869d38-3fac-480a-88d0-5e352265406a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Repo already present: /content/drive/MyDrive/cardiometabolic-risk-colab\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "repo_dir = Path('/content/drive/MyDrive/cardiometabolic-risk-colab')\n",
        "repo_url = \"https://github.com/Yendoh-Derek/Cardiometabolic-Risk-System-for-Wearables.git\"\n",
        "\n",
        "if not repo_dir.exists():\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, str(repo_dir)], check=True)\n",
        "    print(f\"âœ… Repo cloned: {repo_dir}\")\n",
        "else:\n",
        "    print(f\"âœ… Repo already present: {repo_dir}\")\n",
        "\n",
        "os.chdir(repo_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7H95R-4Arel"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7chUG4kwArel",
        "outputId": "dda1a31a-5971-41f9-d51a-0b93c15982c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m142.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m708.4/708.4 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.4/536.4 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.5/253.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.2/779.2 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt -q\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OYJo0mRd4fa",
        "outputId": "fff0c0d7-9196-4990-e3f5-9a3a85e86374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/12.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/12.7 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/12.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m262.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/160.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hipython 7.34.0 requires jedi, which is not installed.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==2.2.2 wfdb==4.1.2 -q\n",
        "!pip check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI8inhgtArem"
      },
      "source": [
        "## Verify GPU & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNV_KZbvArem",
        "outputId": "8c63a9b1-8ec2-4e80-b16b-fa50ce73342f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4\n",
            "\n",
            "âœ… GPU available: True\n",
            "   Device: Tesla T4\n",
            "   Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
        "\n",
        "import torch\n",
        "print(f\"\\nâœ… GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DAeIhrHAren",
        "outputId": "9aaa4276-7877-4078-bf53-f418781bac95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful\n",
            "âœ… Config loaded\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, str(repo_dir / \"colab_src\"))\n",
        "\n",
        "from colab_src.models.ssl.config import SSLConfig\n",
        "from colab_src.models.ssl.encoder import ResNetEncoder\n",
        "from colab_src.models.ssl.decoder import ResNetDecoder\n",
        "from colab_src.models.ssl.losses import SSLLoss\n",
        "\n",
        "print(\"âœ… All imports successful\")\n",
        "\n",
        "# Load config\n",
        "cfg = SSLConfig.from_yaml(\"configs/ssl_pretraining.yaml\")\n",
        "print(f\"âœ… Config loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxgpclroAreo"
      },
      "source": [
        "## Verify Data Integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v7puwptAreo",
        "outputId": "5d6ac9c7-42e4-4ad7-fb3a-8a0eac03445f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Checking data integrity...\n",
            "\n",
            "âœ… ssl_pretraining_data.parquet             (   0.2 MB) â€” Training metadata\n",
            "âœ… ssl_validation_data.parquet              (   0.0 MB) â€” Validation metadata\n",
            "âœ… denoised_signals                         ( 4420 files) â€” Ground truth signals (denoised)\n",
            "\n",
            "âœ… Training dataset: 4133 samples\n",
            "âœ… Validation dataset: 200 samples\n",
            "\n",
            "======================================================================\n",
            "âœ… ALL DATA READY FOR TRAINING\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_dir = COLAB_DRIVE_PATH / \"data\" / \"processed\"\n",
        "\n",
        "# If in Colab, symlink Drive data to repo structure\n",
        "try:\n",
        "    drive_data = COLAB_DRIVE_PATH / \"data\" / \"processed\"\n",
        "    if drive_data.exists() and not data_dir.exists():\n",
        "        print(f\"Linking Drive data: {drive_data} â†’ {data_dir}\")\n",
        "        subprocess.run([\"ln\", \"-s\", str(drive_data), str(data_dir)], check=True)\n",
        "except Exception as e:\n",
        "    print(f\"Warning: {e}\")\n",
        "\n",
        "# Verify Phase 5A windowed data (617K Ã— 1,250 samples)\n",
        "required_files = {\n",
        "    \"mimic_windows_metadata.parquet\": \"Window metadata (653K rows Ã— train/val split)\",\n",
        "    \"mimic_windows.npy\": \"Window signal array [653716, 1250]\",\n",
        "    \"denoised_signal_index.json\": \"Signal index mapping (source signal ID â†’ window rows)\",\n",
        "}\n",
        "\n",
        "print(\"ğŸ” Checking Phase 5A windowed data integrity...\\n\")\n",
        "all_present = True\n",
        "\n",
        "for fname, description in required_files.items():\n",
        "    fpath = data_dir / fname\n",
        "    if fpath.exists():\n",
        "        if fpath.is_dir():\n",
        "            count = len(list(fpath.glob(\"*.npy\")))\n",
        "            print(f\"âœ… {fname:40s} ({count:5d} files) â€” {description}\")\n",
        "        else:\n",
        "            size_mb = fpath.stat().st_size / 1e6\n",
        "            print(f\"âœ… {fname:40s} ({size_mb:6.1f} MB) â€” {description}\")\n",
        "    else:\n",
        "        print(f\"âŒ {fname:40s} NOT FOUND â€” {description}\")\n",
        "        all_present = False\n",
        "\n",
        "if not all_present:\n",
        "    print(\"\\nâš ï¸  MISSING PHASE 5A DATA\")\n",
        "    print(\"\\nTo generate windows from denoised signals:\")\n",
        "    print(\"  1. Run: colab_src/data_pipeline/generate_mimic_windows.py\")\n",
        "    print(\"  2. Input: data/processed/denoised_signal_index.json\")\n",
        "    print(\"  3. Output: data/processed/mimic_windows.npy + mimic_windows_metadata.parquet\")\n",
        "    print(\"\\nOr upload pre-generated data to Google Drive:\")\n",
        "    print(f\"  Path: /MyDrive/cardiometabolic-risk-colab/data/processed/\")\n",
        "    raise FileNotFoundError(\"Phase 5A window data not found\")\n",
        "\n",
        "# Verify Phase 5A window metadata\n",
        "windows_meta = pd.read_parquet(data_dir / \"mimic_windows_metadata.parquet\")\n",
        "print(f\"\\nâœ… Window metadata: {len(windows_meta)} total rows\")\n",
        "print(f\"   Columns: {list(windows_meta.columns)}\")\n",
        "if 'split' in windows_meta.columns:\n",
        "    print(f\"   Train/Val split: {windows_meta['split'].value_counts().to_dict()}\")\n",
        "\n",
        "# Check window signals (use memmap to avoid loading all 653K into memory)\n",
        "windows_path = data_dir / \"mimic_windows.npy\"\n",
        "windows_memmap = np.load(windows_path, mmap_mode='r')\n",
        "print(f\"\\nâœ… Window signals: shape {windows_memmap.shape}\")\n",
        "assert windows_memmap.shape == (653716, 1250), f\"Shape mismatch! Expected (653716, 1250), got {windows_memmap.shape}\"\n",
        "print(f\"   Signal format: 653716 windows Ã— 1250 samples per window (10 sec @ 125 Hz)\")\n",
        "print(f\"   Memory usage (mmap): {windows_path.stat().st_size / 1e9:.2f} GB\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… PHASE 5A WINDOWED DATA READY FOR TRAINING\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Progress Tracking Setup\n",
        "Monitor training progress with real-time metrics and ETA estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import progress tracking modules\n",
        "from colab_src.utils.progress_tracker import TrainingProgressTracker, monitor_training_live\n",
        "\n",
        "# Initialize progress tracker\n",
        "tracker = TrainingProgressTracker(\n",
        "    output_dir=\"logs/training\",\n",
        "    name=\"SSL Pretraining Phase 5B\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol0Z5x-vhaHo"
      },
      "source": [
        "### Temporary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OokiiRJ3hcKR",
        "outputId": "449cd3af-476f-406f-fbd5-cee1374a331e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Training history found!\n",
            "   Epochs completed: 23\n",
            "   Best val loss: 0.2626\n",
            "   Final train loss: 0.2748\n",
            "âœ… Best model checkpoint saved: /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints/ssl/best_model.pt\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "repo_dir = Path(\"/content/drive/MyDrive/cardiometabolic-risk-colab\")\n",
        "\n",
        "# Check training history\n",
        "history_file = repo_dir / \"logs/ssl/training_history.json\"\n",
        "if history_file.exists():\n",
        "    with open(history_file) as f:\n",
        "        history = json.load(f)\n",
        "    print(f\"âœ… Training history found!\")\n",
        "    print(f\"   Epochs completed: {len(history['train_loss'])}\")\n",
        "    print(f\"   Best val loss: {min(history['val_loss']):.4f}\")\n",
        "    print(f\"   Final train loss: {history['train_loss'][-1]:.4f}\")\n",
        "else:\n",
        "    print(\"âŒ Training history not found\")\n",
        "\n",
        "# Check checkpoint\n",
        "checkpoint_file = repo_dir / \"checkpoints/ssl/best_model.pt\"\n",
        "if checkpoint_file.exists():\n",
        "    print(f\"âœ… Best model checkpoint saved: {checkpoint_file}\")\n",
        "else:\n",
        "    print(\"âŒ Checkpoint not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYk4Kv-TiFf8",
        "outputId": "5a1dbc94-772c-42f2-c6fa-b95c78e48f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training stopped at epoch 23\n",
            "Early stopping likely triggered (patience exhausted)\n",
            "\n",
            "Validation loss by epoch:\n",
            "  Epoch 19: train=0.2771, val=0.2630\n",
            "  Epoch 20: train=0.2774, val=0.2630\n",
            "  Epoch 21: train=0.2769, val=0.2631\n",
            "  Epoch 22: train=0.2742, val=0.2630\n",
            "  Epoch 23: train=0.2748, val=0.2632\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "repo_dir = Path(\"/content/drive/MyDrive/cardiometabolic-risk-colab\")\n",
        "history_file = repo_dir / \"logs/ssl/training_history.json\"\n",
        "\n",
        "with open(history_file) as f:\n",
        "    history = json.load(f)\n",
        "\n",
        "print(f\"Training stopped at epoch {len(history['train_loss'])}\")\n",
        "print(f\"Early stopping likely triggered (patience exhausted)\")\n",
        "print(f\"\\nValidation loss by epoch:\")\n",
        "for i, (train, val) in enumerate(zip(history['train_loss'][-5:], history['val_loss'][-5:]),\n",
        "                                   start=len(history['train_loss'])-4):\n",
        "    print(f\"  Epoch {i}: train={train:.4f}, val={val:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-es4rfwArep"
      },
      "source": [
        "## Phase 5: Run Full Training (50 Epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fudemifvAreq",
        "outputId": "15c74a1f-9e8c-492b-8248-52169b86ed3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Checkpoints will be saved to:\n",
            "   /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints\n",
            "\n",
            "â±ï¸  Estimated duration: 8â€“12 hours\n",
            "ğŸ’¾ Batch size: 8 (with 4Ã— accumulation = eff. 32)\n",
            "ğŸ”¢ Epochs: 50\n",
            "ğŸ“Š Training samples: 4,133\n",
            "\n",
            "======================================================================\n",
            "Starting training...\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create output directory for checkpoints\n",
        "checkpoint_dir = COLAB_DRIVE_PATH / \"checkpoints\"\n",
        "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“ Checkpoints will be saved to:\")\n",
        "print(f\"   {checkpoint_dir}\")\n",
        "print(f\"\\nâ±ï¸  Estimated duration: 8â€“12 hours\")\n",
        "print(f\"ğŸ’¾ Batch size: 8 (with 4Ã— accumulation = eff. 32)\")\n",
        "print(f\"ğŸ”¢ Epochs: 50\")\n",
        "print(f\"ğŸ“Š Training samples: 4,133\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA3QNvfsAreq",
        "outputId": "fa650710-f3c6-4a82-cd5e-360778b6a9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting Phase 5 training...\n",
            "\n",
            "Command: /usr/bin/python3 -m colab_src.models.ssl.train --config /content/drive/MyDrive/cardiometabolic-risk-colab/configs/ssl_pretraining.yaml --data-dir /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed --epochs 50\n",
            "\n",
            "======================================================================\n",
            "2026-01-13 08:49:23,457 - __main__ - INFO - Loading config from /content/drive/MyDrive/cardiometabolic-risk-colab/configs/ssl_pretraining.yaml\n",
            "2026-01-13 08:49:23,797 - __main__ - INFO - âœ… Auto-detected GPU: Tesla T4\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO - Data directory overridden: /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO - \n",
            "============================================================\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO - Configuration:\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Device:              cuda\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Data dir:            /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Epochs:              50\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Batch size:          8\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Accumulation steps:  4\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO -   Mixed precision:     False\n",
            "2026-01-13 08:49:23,798 - __main__ - INFO - ============================================================\n",
            "\n",
            "2026-01-13 08:49:23,801 - __main__ - INFO - Building encoder-decoder model...\n",
            "2026-01-13 08:49:24,170 - __main__ - INFO - Model parameters: 3,966,849 (3,966,849 trainable)\n",
            "2026-01-13 08:49:29,019 - __main__ - INFO - \n",
            "Validating data paths:\n",
            "2026-01-13 08:49:29,019 - __main__ - INFO -   âœ“ Train: /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/ssl_pretraining_data.parquet\n",
            "2026-01-13 08:49:29,020 - __main__ - INFO -   âœ“ Val:   /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/ssl_validation_data.parquet\n",
            "2026-01-13 08:49:29,020 - __main__ - WARNING -   âš  Test not found: /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/ssl_test_data.parquet (will skip test)\n",
            "2026-01-13 08:49:29,020 - __main__ - INFO -   âœ“ Denoised index: /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/denoised_signal_index.json\n",
            "2026-01-13 08:49:29,020 - __main__ - INFO - \n",
            "Creating dataloaders...\n",
            "2026-01-13 08:49:29,437 - colab_src.models.ssl.dataloader - INFO - Loaded denoised signal index: 4417 entries\n",
            "2026-01-13 08:49:29,437 - colab_src.models.ssl.dataloader - INFO - PPGDataset initialized: 4133 samples from /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/ssl_pretraining_data.parquet\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2026-01-13 08:49:29,452 - colab_src.models.ssl.dataloader - INFO - Loaded denoised signal index: 4417 entries\n",
            "2026-01-13 08:49:29,452 - colab_src.models.ssl.dataloader - INFO - PPGDataset initialized: 200 samples from /content/drive/MyDrive/cardiometabolic-risk-colab/data/processed/ssl_validation_data.parquet\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2026-01-13 08:49:29,452 - colab_src.models.ssl.dataloader - INFO - DataLoaders created:\n",
            "2026-01-13 08:49:29,452 - colab_src.models.ssl.dataloader - INFO -   Train: 4133 samples\n",
            "2026-01-13 08:49:29,452 - colab_src.models.ssl.dataloader - INFO -   Val:   200 samples\n",
            "2026-01-13 08:49:29,452 - __main__ - INFO - DataLoaders created successfully\n",
            "\n",
            "/content/drive/MyDrive/cardiometabolic-risk-colab/colab_src/models/ssl/trainer.py:77: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler(enabled=use_mixed_precision)\n",
            "2026-01-13 08:49:29,830 - __main__ - INFO - ============================================================\n",
            "2026-01-13 08:49:29,830 - __main__ - INFO - ğŸš€ Starting training loop (50 epochs)\n",
            "2026-01-13 08:49:29,830 - __main__ - INFO - ============================================================\n",
            "\n",
            "2026-01-13 08:49:29,831 - colab_src.models.ssl.trainer - INFO - Starting training for 50 epochs on cuda\n",
            "2026-01-13 08:49:29,831 - colab_src.models.ssl.trainer - INFO - Gradient accumulation: 4 steps\n",
            "2026-01-13 08:49:29,831 - colab_src.models.ssl.trainer - INFO - Mixed precision: False\n",
            "/content/drive/MyDrive/cardiometabolic-risk-colab/colab_src/models/ssl/trainer.py:108: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.use_mixed_precision):\n",
            "2026-01-13 08:51:24,980 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 1.5397\n",
            "2026-01-13 08:53:09,635 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.9908\n",
            "2026-01-13 08:54:52,897 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.7861\n",
            "2026-01-13 08:56:35,517 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.6788\n",
            "2026-01-13 08:58:18,279 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.6129\n",
            "/content/drive/MyDrive/cardiometabolic-risk-colab/colab_src/models/ssl/trainer.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=self.use_mixed_precision):\n",
            "2026-01-13 08:58:47,393 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 08:58:47,393 - colab_src.models.ssl.trainer - INFO - Epoch 1/50 [2.0%]\n",
            "2026-01-13 08:58:47,393 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.6123\n",
            "2026-01-13 08:58:47,393 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2618\n",
            "2026-01-13 08:58:47,393 - colab_src.models.ssl.trainer - INFO -   LR:         9.96e-04\n",
            "2026-01-13 08:58:52,961 - colab_src.models.ssl.trainer - INFO - Checkpoint saved: /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints/ssl/best_model.pt\n",
            "2026-01-13 08:58:52,962 - colab_src.models.ssl.trainer - INFO -   âœ“ Best model updated (loss: 0.2618)\n",
            "2026-01-13 08:59:11,171 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3305\n",
            "2026-01-13 08:59:28,064 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3320\n",
            "2026-01-13 08:59:45,214 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3317\n",
            "2026-01-13 09:00:02,453 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3287\n",
            "2026-01-13 09:00:19,805 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3282\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO - Epoch 2/50 [4.0%]\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3283\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2695\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO -   LR:         9.84e-04\n",
            "2026-01-13 09:00:22,623 - colab_src.models.ssl.trainer - INFO -   Patience: 1/10\n",
            "2026-01-13 09:00:40,600 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3318\n",
            "2026-01-13 09:00:58,192 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3327\n",
            "2026-01-13 09:01:15,877 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3270\n",
            "2026-01-13 09:01:33,647 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3289\n",
            "2026-01-13 09:01:51,446 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3310\n",
            "2026-01-13 09:01:53,752 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:01:53,752 - colab_src.models.ssl.trainer - INFO - Epoch 3/50 [6.0%]\n",
            "2026-01-13 09:01:53,752 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3312\n",
            "2026-01-13 09:01:53,752 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2789\n",
            "2026-01-13 09:01:53,753 - colab_src.models.ssl.trainer - INFO -   LR:         9.65e-04\n",
            "2026-01-13 09:01:53,753 - colab_src.models.ssl.trainer - INFO -   Patience: 2/10\n",
            "2026-01-13 09:02:12,008 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3493\n",
            "2026-01-13 09:02:29,985 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3329\n",
            "2026-01-13 09:02:48,004 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3256\n",
            "2026-01-13 09:03:05,927 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3227\n",
            "2026-01-13 09:03:23,802 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3210\n",
            "2026-01-13 09:03:26,508 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:03:26,508 - colab_src.models.ssl.trainer - INFO - Epoch 4/50 [8.0%]\n",
            "2026-01-13 09:03:26,508 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3210\n",
            "2026-01-13 09:03:26,509 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2622\n",
            "2026-01-13 09:03:26,509 - colab_src.models.ssl.trainer - INFO -   LR:         9.39e-04\n",
            "2026-01-13 09:03:26,509 - colab_src.models.ssl.trainer - INFO -   Patience: 3/10\n",
            "2026-01-13 09:03:44,845 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3118\n",
            "2026-01-13 09:04:02,862 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3159\n",
            "2026-01-13 09:04:20,933 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3166\n",
            "2026-01-13 09:04:38,928 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3146\n",
            "2026-01-13 09:04:56,950 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3117\n",
            "2026-01-13 09:04:59,273 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:04:59,273 - colab_src.models.ssl.trainer - INFO - Epoch 5/50 [10.0%]\n",
            "2026-01-13 09:04:59,273 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3117\n",
            "2026-01-13 09:04:59,274 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2621\n",
            "2026-01-13 09:04:59,274 - colab_src.models.ssl.trainer - INFO -   LR:         9.05e-04\n",
            "2026-01-13 09:04:59,274 - colab_src.models.ssl.trainer - INFO -   Patience: 4/10\n",
            "2026-01-13 09:05:18,019 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3031\n",
            "2026-01-13 09:05:36,067 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3030\n",
            "2026-01-13 09:05:54,117 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3041\n",
            "2026-01-13 09:06:12,197 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3062\n",
            "2026-01-13 09:06:30,290 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3055\n",
            "2026-01-13 09:06:32,746 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:06:32,747 - colab_src.models.ssl.trainer - INFO - Epoch 6/50 [12.0%]\n",
            "2026-01-13 09:06:32,747 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3057\n",
            "2026-01-13 09:06:32,747 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2627\n",
            "2026-01-13 09:06:32,747 - colab_src.models.ssl.trainer - INFO -   LR:         8.66e-04\n",
            "2026-01-13 09:06:32,747 - colab_src.models.ssl.trainer - INFO -   Patience: 5/10\n",
            "2026-01-13 09:06:51,172 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3011\n",
            "2026-01-13 09:07:09,237 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.2989\n",
            "2026-01-13 09:07:27,229 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.2995\n",
            "2026-01-13 09:07:45,157 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.2996\n",
            "2026-01-13 09:08:03,298 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3023\n",
            "2026-01-13 09:08:06,204 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:08:06,204 - colab_src.models.ssl.trainer - INFO - Epoch 7/50 [14.0%]\n",
            "2026-01-13 09:08:06,204 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3022\n",
            "2026-01-13 09:08:06,205 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2714\n",
            "2026-01-13 09:08:06,205 - colab_src.models.ssl.trainer - INFO -   LR:         8.21e-04\n",
            "2026-01-13 09:08:06,205 - colab_src.models.ssl.trainer - INFO -   Patience: 6/10\n",
            "2026-01-13 09:08:24,676 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3013\n",
            "2026-01-13 09:08:42,718 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.2979\n",
            "2026-01-13 09:09:00,821 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.2977\n",
            "2026-01-13 09:09:18,875 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3012\n",
            "2026-01-13 09:09:36,860 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3004\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO - Epoch 8/50 [16.0%]\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3004\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2927\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO -   LR:         7.70e-04\n",
            "2026-01-13 09:09:39,166 - colab_src.models.ssl.trainer - INFO -   Patience: 7/10\n",
            "2026-01-13 09:09:57,941 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.2941\n",
            "2026-01-13 09:10:15,944 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.2974\n",
            "2026-01-13 09:10:33,968 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3027\n",
            "2026-01-13 09:10:52,030 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3129\n",
            "2026-01-13 09:11:10,093 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3130\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO - Epoch 9/50 [18.0%]\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3128\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.3271\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO -   LR:         7.16e-04\n",
            "2026-01-13 09:11:12,405 - colab_src.models.ssl.trainer - INFO -   Patience: 8/10\n",
            "2026-01-13 09:11:30,804 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.3091\n",
            "2026-01-13 09:11:48,872 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.3072\n",
            "2026-01-13 09:12:06,882 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.3055\n",
            "2026-01-13 09:12:24,940 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.3042\n",
            "2026-01-13 09:12:43,001 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.3044\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO - Epoch 10/50 [20.0%]\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.3044\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.6486\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO -   LR:         6.58e-04\n",
            "2026-01-13 09:12:46,104 - colab_src.models.ssl.trainer - INFO -   Patience: 9/10\n",
            "2026-01-13 09:12:51,793 - colab_src.models.ssl.trainer - INFO - Checkpoint saved: /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints/ssl/checkpoint_epoch_010.pt\n",
            "2026-01-13 09:13:10,869 - colab_src.models.ssl.trainer - INFO -   Batch 103/516: Loss = 0.2941\n",
            "2026-01-13 09:13:29,396 - colab_src.models.ssl.trainer - INFO -   Batch 206/516: Loss = 0.2916\n",
            "2026-01-13 09:13:47,476 - colab_src.models.ssl.trainer - INFO -   Batch 309/516: Loss = 0.2910\n",
            "2026-01-13 09:14:05,294 - colab_src.models.ssl.trainer - INFO -   Batch 412/516: Loss = 0.2916\n",
            "2026-01-13 09:14:23,251 - colab_src.models.ssl.trainer - INFO -   Batch 515/516: Loss = 0.2927\n",
            "2026-01-13 09:14:25,556 - colab_src.models.ssl.trainer - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO - Epoch 11/50 [22.0%]\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO -   Train Loss: 0.2927\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO -   Val Loss:   0.2914\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO -   LR:         5.98e-04\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO -   Patience: 10/10\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO - Early stopping triggered at epoch 11\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO - \n",
            "Training completed!\n",
            "2026-01-13 09:14:25,557 - colab_src.models.ssl.trainer - INFO - Best epoch: 1 (val_loss: 0.2618)\n",
            "2026-01-13 09:14:25,564 - colab_src.models.ssl.trainer - INFO - Training history saved to /content/drive/MyDrive/cardiometabolic-risk-colab/logs/ssl/training_history.json\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO - \n",
            "============================================================\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO - âœ… Training completed successfully!\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO -    Best validation loss: 0.261843\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO -    Best epoch: 1\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO -    Checkpoint dir: /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints/ssl\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO -    Log dir: /content/drive/MyDrive/cardiometabolic-risk-colab/logs/ssl\n",
            "2026-01-13 09:14:25,564 - __main__ - INFO - ============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "\n",
            "âœ… Training completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Run training script with auto-detect device\n",
        "tracker.start()\n",
        "\n",
        "cmd = [\n",
        "    sys.executable,\n",
        "    \"-m\",\n",
        "    \"colab_src.models.ssl.train\",\n",
        "    \"--config\", str(repo_dir / \"configs/ssl_pretraining.yaml\"),\n",
        "    \"--data-dir\", str(data_dir),\n",
        "    \"--epochs\", \"50\",\n",
        "    \"--log-dir\", str(repo_dir / \"logs/training\"),\n",
        "    \"--checkpoint-dir\", str(repo_dir / \"checkpoints/ssl\"),\n",
        "]\n",
        "\n",
        "print(f\"ğŸš€ Starting Phase 5B training...\\n\")\n",
        "print(f\"Command: {' '.join(cmd)}\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Run training with progress tracking\n",
        "result = subprocess.run(cmd, cwd=str(repo_dir), capture_output=True, text=True)\n",
        "\n",
        "# Display training output\n",
        "training_output = result.stderr  # Training logs go to stderr\n",
        "print(training_output)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nâœ… Training completed successfully!\")\n",
        "    tracker.summary()\n",
        "else:\n",
        "    print(f\"\\nâŒ Training failed with exit code: {result.returncode}\")\n",
        "    print(\"See output above for error details\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YnYU2opN5T-"
      },
      "source": [
        "### Temperary diagnostic cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxWt6G7PPnVy",
        "outputId": "507b8878-163a-48a8-9e4f-e6213cf45bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pulling latest changes from GitHub...\n",
            "Updating c2dda54..b3de6c5\n",
            "Fast-forward\n",
            " configs/ssl_pretraining.yaml | 2 +-\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "\n",
            "âœ… Code updated successfully!\n"
          ]
        }
      ],
      "source": [
        "# Pull latest code from GitHub\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "repo_dir = Path('/content/drive/MyDrive/cardiometabolic-risk-colab')\n",
        "\n",
        "print(\"Pulling latest changes from GitHub...\")\n",
        "result = subprocess.run(\n",
        "    [\"git\", \"pull\", \"origin\", \"main\"],\n",
        "    cwd=str(repo_dir),\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(result.stdout)\n",
        "if result.returncode == 0:\n",
        "    print(\"âœ… Code updated successfully!\")\n",
        "else:\n",
        "    print(f\"âš ï¸  Error: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-Time Progress Monitoring\n",
        "Monitor training while it runs by reading the live progress file (execute during training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run live monitoring (updates every 5 seconds from training_history.json)\n",
        "monitor_training_live(history_file=\"logs/training/training_history.json\", update_interval=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Y3KM3qAreq"
      },
      "source": [
        "## Validate & Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss-_tbGRArer",
        "outputId": "c5040672-66c3-47d4-e5ca-8c560ae5b511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸  Metrics file not found: /content/drive/MyDrive/cardiometabolic-risk-colab/checkpoints/training_metrics.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load training metrics from progress tracker\n",
        "history_file = Path(\"logs/training/training_history.json\")\n",
        "\n",
        "if history_file.exists():\n",
        "    with open(history_file) as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    # Create comprehensive visualization\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # 1. Main loss curves\n",
        "    ax1 = fig.add_subplot(gs[0, :2])\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    ax1.plot(epochs, history['train_loss'], 'o-', linewidth=2, markersize=4, label='Train Loss')\n",
        "    if history.get('val_loss'):\n",
        "        ax1.plot(epochs, history['val_loss'], 's-', linewidth=2, markersize=4, label='Val Loss')\n",
        "        best_idx = history['val_loss'].index(min(history['val_loss']))\n",
        "        ax1.axvline(best_idx + 1, color='green', linestyle='--', alpha=0.5, label=f'Best @ Epoch {best_idx + 1}')\n",
        "    ax1.set_xlabel('Epoch', fontsize=11)\n",
        "    ax1.set_ylabel('Loss', fontsize=11)\n",
        "    ax1.set_title('Training & Validation Loss', fontsize=13, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # 2. Loss improvement\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    initial_loss = history['train_loss'][0]\n",
        "    improvements = [(initial_loss - l) / initial_loss * 100 for l in history['train_loss']]\n",
        "    ax2.plot(epochs, improvements, 'o-', color='green', linewidth=2, markersize=4)\n",
        "    ax2.set_xlabel('Epoch', fontsize=11)\n",
        "    ax2.set_ylabel('Improvement (%)', fontsize=11)\n",
        "    ax2.set_title('Loss Improvement', fontsize=13, fontweight='bold')\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    # 3. Loss per epoch (bar chart)\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    ax3.bar(epochs, history['train_loss'], alpha=0.7, color='steelblue')\n",
        "    ax3.set_xlabel('Epoch', fontsize=11)\n",
        "    ax3.set_ylabel('Train Loss', fontsize=11)\n",
        "    ax3.set_title('Train Loss per Epoch', fontsize=13, fontweight='bold')\n",
        "    ax3.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    # 4. Validation loss per epoch\n",
        "    if history.get('val_loss'):\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        ax4.bar(epochs, history['val_loss'], alpha=0.7, color='coral')\n",
        "        best_val = min(history['val_loss'])\n",
        "        ax4.axhline(best_val, color='green', linestyle='--', alpha=0.5, linewidth=2)\n",
        "        ax4.set_xlabel('Epoch', fontsize=11)\n",
        "        ax4.set_ylabel('Val Loss', fontsize=11)\n",
        "        ax4.set_title('Validation Loss per Epoch', fontsize=13, fontweight='bold')\n",
        "        ax4.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    # 5. Statistics\n",
        "    ax5 = fig.add_subplot(gs[1, 2])\n",
        "    ax5.axis('off')\n",
        "    stats_text = f\"\"\"\n",
        "    ğŸ“Š TRAINING STATISTICS\n",
        "    \n",
        "    Total Epochs: {len(history['train_loss'])}\n",
        "    Best Epoch: {history.get('best_epoch', 'N/A')}\n",
        "    Min Train Loss: {min(history['train_loss']):.4f}\n",
        "    Final Train Loss: {history['train_loss'][-1]:.4f}\n",
        "    \"\"\"\n",
        "    if history.get('val_loss'):\n",
        "        stats_text += f\"\\n    Min Val Loss: {min(history['val_loss']):.4f}\\n    Final Val Loss: {history['val_loss'][-1]:.4f}\"\n",
        "    ax5.text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center', family='monospace')\n",
        "\n",
        "    # 6. Convergence analysis\n",
        "    ax6 = fig.add_subplot(gs[2, :])\n",
        "    window = 5\n",
        "    if len(history['train_loss']) >= window:\n",
        "        smoothed = np.convolve(history['train_loss'], np.ones(window)/window, mode='valid')\n",
        "        ax6.plot(range(1, len(smoothed) + 1), smoothed, 'b-', linewidth=3, label=f'Smoothed (window={window})')\n",
        "    ax6.plot(epochs, history['train_loss'], 'o-', linewidth=1, markersize=3, alpha=0.5, label='Raw')\n",
        "    if history.get('val_loss'):\n",
        "        if len(history['val_loss']) >= window:\n",
        "            smoothed_val = np.convolve(history['val_loss'], np.ones(window)/window, mode='valid')\n",
        "            ax6.plot(range(1, len(smoothed_val) + 1), smoothed_val, 'r-', linewidth=3, label='Val Smoothed')\n",
        "        ax6.plot(epochs, history['val_loss'], 's-', linewidth=1, markersize=3, alpha=0.5, label='Val Raw')\n",
        "    ax6.set_xlabel('Epoch', fontsize=11)\n",
        "    ax6.set_ylabel('Loss', fontsize=11)\n",
        "    ax6.set_title('Convergence Analysis (Smoothed Loss Curves)', fontsize=13, fontweight='bold')\n",
        "    ax6.legend()\n",
        "    ax6.grid(alpha=0.3)\n",
        "\n",
        "    plt.savefig('artifacts/training_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"âœ… Training analysis visualization saved to artifacts/training_analysis.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"âš ï¸  Training history not found: {history_file}\")\n",
        "    print(\"Run training cell first (Cell 20)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmZjzWYtArer"
      },
      "source": [
        "## âœ… Phase 5 Complete\n",
        "\n",
        "Checkpoints are saved to Google Drive at:\n",
        "```\n",
        "/MyDrive/cardiometabolic-risk-colab/phase5_checkpoints/\n",
        "```\n",
        "\n",
        "**Next Steps**:\n",
        "1. Phase 6: Linear probe evaluation\n",
        "2. Phase 7: Extract embeddings\n",
        "3. Phase 8: Train XGBoost models\n",
        "\n",
        "See [README.md](../README.md) for detailed instructions."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "05_ssl_pretraining_colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
