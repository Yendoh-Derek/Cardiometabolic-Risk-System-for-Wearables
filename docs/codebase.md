# Cardiometabolic Risk Estimation â€” Codebase Structure (Phase 5B In Execution)

**Updated**: January 20, 2026  
**Status**: Phase 5B Training In Progress  
**Architecture**: Self-Supervised Learning on 653,716 Overlapping 10-Second Windows â†’ Transfer Learning Validation on VitalDB

---

## ðŸ”„ CRITICAL PIVOT: Window Size & Architecture Changes (Phase 5A Complete)

| Parameter            | Old (Phase 4)           | New (Phase 5+)              | Status               | Rationale                                               |
| -------------------- | ----------------------- | --------------------------- | -------------------- | ------------------------------------------------------- |
| **Window size**      | 75,000 samples (10 min) | 1,250 samples (10 sec)      | âœ… Implemented       | Preserve micro-morphology, reduce over-compression      |
| **Encoder blocks**   | 4                       | 3                           | âœ… Verified          | Prevent excessive downsampling of 1,250-sample input    |
| **Training samples** | 4,133 signals           | 653,716 overlapping windows | âœ… Generated         | 60Ã— data expansion via stride-500 sliding window        |
| **Batch size**       | 8                       | **128**                     | âœ… Confirmed in code | GPU utilization, better BatchNorm, 10Ã— faster epochs    |
| **FFT padding**      | 2^17 (131,072)          | **2^11 (2,048)**            | âœ… Verified in code  | 67Ã— faster loss computation, eliminate 99% zero-padding |
| **Data split**       | Window-level            | **Subject-level (STRING)**  | âœ… Confirmed in code | Prevent data leakage in Phase 8 transfer learning       |

---

## Project Directory Structure

```
cardiometabolic-risk-colab/
â”‚
â”œâ”€â”€ docs/ # Documentation (Updated January 20, 2026 - Cleaned up)
â”‚ â”œâ”€â”€ PROJECT_STATUS.md # âœ… Master status - Phase 5B current
â”‚ â”œâ”€â”€ architecture.md # System design (complete)
â”‚ â”œâ”€â”€ codebase.md # This file (structure reference)
â”‚ â”œâ”€â”€ IMPLEMENTATION_PLAN_PHASES_0-8.md # Master roadmap
â”‚ â””â”€â”€ PHASE_5A_COMPLETE.txt # Phase 5A completion marker
â”‚
â”‚ [REMOVED - January 20, 2026: 14 obsolete .md files]
â”‚ [architecture_old.md, codebase_old.md, CRITICAL_FIXES_APPLIED.md, etc.]
â”‚
â”œâ”€â”€ colab_src/ # Core Python modules (SSL pretraining)
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚
â”‚ â”œâ”€â”€ models/ssl/ # Self-Supervised Learning (Phase 5)
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ encoder.py # ResNetEncoder: [B,1,1250] â†’ [B,512] (3 blocks)
â”‚ â”‚ â”œâ”€â”€ decoder.py # ResNetDecoder: [B,512] â†’ [B,1,1250] (mirror architecture)
â”‚ â”‚ â”œâ”€â”€ losses.py # Hybrid loss: MSE(50%) + SSIM(30%) + FFT(20%)
â”‚ â”‚ â”œâ”€â”€ augmentation.py # PPGAugmentation: temporal shift, amplitude scale, noise, baseline wander
â”‚ â”‚ â”œâ”€â”€ dataloader.py # PPGDataset: lazy-load 653,716 windowed samples with SQI filtering
â”‚ â”‚ â”œâ”€â”€ trainer.py # Training loop with checkpoint-resume & gradient accumulation
â”‚ â”‚ â”œâ”€â”€ train.py # CLI entry point for Phase 5B (Colab)
â”‚ â”‚ â”œâ”€â”€ config.py # YAML config loader
â”‚ â”‚ â””â”€â”€ vitaldb_transfer.py # Phase 8: VitalDB linear probes
â”‚ â”‚
â”‚ â”œâ”€â”€ data_pipeline/ # Data preparation (Phases 0-5)
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ mimic_ingestion.py # Download 4,417 MIMIC PPG signals (@125Hz, 75k samples each)
â”‚ â”‚ â”œâ”€â”€ signal_preprocessing.py # Chebyshev-II filter, wavelet denoising
â”‚ â”‚ â”œâ”€â”€ signal_quality.py # SQI scoring
â”‚ â”‚ â”œâ”€â”€ generate_mimic_windows.py # NEW: Generate 617k overlapping 1,250-sample windows
â”‚ â”‚ â”œâ”€â”€ demographic_processor.py # Extract age, sex, BMI (minimal â€” no clinical labels)
â”‚ â”‚ â””â”€â”€ dataset_assembly.py # Combine signals + metadata into parquet
â”‚ â”‚
â”‚ â”œâ”€â”€ signal_processing/ # Signal utilities
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ filters.py # Chebyshev-II bandpass [0.5â€“8 Hz]
â”‚ â”‚ â”œâ”€â”€ denoising.py # Wavelet decomposition (db4, level 5)
â”‚ â”‚ â”œâ”€â”€ segmentation.py # Sliding window extraction
â”‚ â”‚ â””â”€â”€ quality_metrics.py # SQI, SNR, perfusion index
â”‚ â”‚
â”‚ â”œâ”€â”€ features/ # Classical feature extraction (Phase 7)
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ hrv_features.py # HRV (28 features: time, frequency, nonlinear)
â”‚ â”‚ â”œâ”€â”€ morphology_features.py # PPG morphology (6 features: systolic height, diastolic area, etc.)
â”‚ â”‚ â”œâ”€â”€ clinical_context.py # Context encoding (3 features: age, sex, BMI)
â”‚ â”‚ â””â”€â”€ feature_combiner.py # Combine SSL embeddings + classical features
â”‚ â”‚
â”‚ â”œâ”€â”€ validation/ # Quality assurance (Phases 6-8)
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ reconstruction_metrics.py # SSIM, MSE, correlation
â”‚ â”‚ â”œâ”€â”€ embedding_analysis.py # Variance, clustering, PCA visualization
â”‚ â”‚ â””â”€â”€ transfer_learning_eval.py # AUROC, ROC curves, fairness checks
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/ # Shared utilities
â”‚ â”‚ â”œâ”€â”€ __init__.py
â”‚ â”‚ â”œâ”€â”€ config_loader.py # Load configs/ssl_pretraining.yaml
â”‚ â”‚ â”œâ”€â”€ checkpoint_manager.py # Save/load best_encoder.pt
â”‚ â”‚ â”œâ”€â”€ logging.py # MLflow + standard logging
â”‚ â”‚ â””â”€â”€ reproducibility.py # Set seed(42) for all RNGs
â”‚ â”‚
â”‚ â””â”€â”€ evaluation/ # Reporting (Phase 8)
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”œâ”€â”€ vitaldb_validation.py # Cross-subject evaluation, population shift analysis
â”‚ â”œâ”€â”€ report_generator.py # Markdown report with AUROC/CI
â”‚ â””â”€â”€ visualization.py # ROC curves, embedding plots
â”‚
â”œâ”€â”€ data/ # All datasets (Colab storage) - Phase 5A Complete
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ RECORDS-waveforms # MIMIC file index
â”‚ â”‚
â”‚ â”œâ”€â”€ processed/ # âœ… Phase 5A Data
â”‚ â”‚ â”œâ”€â”€ mimic_windows.npy # [653,716 Ã— 1,250] windowed samples (3.04 GB)
â”‚ â”‚ â”œâ”€â”€ mimic_windows_metadata.parquet # Window metadata with subject_id (STRING)
â”‚ â”‚ â”œâ”€â”€ ssl_pretraining_data.parquet # Training split (subject-level, ~520K windows)
â”‚ â”‚ â”œâ”€â”€ ssl_validation_data.parquet # Validation split (subject-level, ~18K windows)
â”‚ â”‚ â”œâ”€â”€ denoised_signal_index.json # Signal ID mapping
â”‚ â”‚ â”œâ”€â”€ denoised_signals/ # Per-file denoised signals (backup)
â”‚ â”‚ â””â”€â”€ ssl_embeddings.npy # Phase 7: [653,716 Ã— 512] window embeddings (future)
â”‚ â”‚
â”‚ â”œâ”€â”€ metadata/
â”‚ â”‚ â”œâ”€â”€ signal_metadata.parquet # 4,417 rows: subject_id, signal_length, sqi_score, snr_db
â”‚ â”‚ â””â”€â”€ vitaldb_labels.parquet # Phase 8: VitalDB cases with hypertension/diabetes/obesity labels
â”‚ â”‚
â”‚ â””â”€â”€ cache/
â”‚ â””â”€â”€ temporary processing files
â”‚
â”œâ”€â”€ checkpoints/ # Model weights (Colab) - Phase 5B In Progress
â”‚ â”œâ”€â”€ ssl/ # â³ Phase 5B checkpoints
â”‚ â”‚ â”œâ”€â”€ best_encoder.pt # Best validation loss model (target)
â”‚ â”‚ â””â”€â”€ checkpoint_epoch_*.pt # Periodic checkpoints (if saving enabled)
â”‚ â”‚
â”‚ â””â”€â”€ phase3/ # Legacy checkpoints (kept for reference)
â”‚ â”œâ”€â”€ checkpoint_pilot.pt # Phase 3 pilot
â”‚ â””â”€â”€ metrics_pilot.json
â”‚
â”œâ”€â”€ artifacts/ # Evaluation outputs
â”‚ â”œâ”€â”€ models/ # Model exports
â”‚ â”‚ â”œâ”€â”€ best_encoder.onnx # Phase 5: Encoder in ONNX format
â”‚ â”‚ â””â”€â”€ vitaldb_transfer_results.json # Phase 8: AUROC per condition
â”‚ â”‚
â”‚ â”œâ”€â”€ evaluation/
â”‚ â”‚ â”œâ”€â”€ reconstruction_metrics.json # Phase 6: SSIM, MSE, correlation
â”‚ â”‚ â”œâ”€â”€ embeddings_visualization.png # Phase 6: 2D PCA colored by SQI
â”‚ â”‚ â”œâ”€â”€ transfer_learning_roc_curves.png # Phase 8: ROC curves
â”‚ â”‚ â””â”€â”€ transfer_learning_report.md # Phase 8: Interpretation & next steps
â”‚ â”‚
â”‚ â””â”€â”€ preprocessing/
â”‚ â”œâ”€â”€ filter_params.json # Chebyshev-II coefficients
â”‚ â””â”€â”€ normalization_stats.json # Mean/std for signal normalization
â”‚
â”œâ”€â”€ configs/ # Configuration files
â”‚ â”œâ”€â”€ ssl_pretraining.yaml # MAIN: Phase 5 config with critical fixes
â”‚ â”‚ # batch_size: 128 (was 8) âœ…
â”‚ â”‚ # fft_pad_size: 2048 (was 131072) âœ…
â”‚ â”‚ # num_blocks: 3 (was 4)
â”‚ â”œâ”€â”€ preprocessing.yaml # Phase 0: Signal preprocessing params
â”‚ â””â”€â”€ data.yaml # Data paths & split ratios
â”‚
â”œâ”€â”€ tests/ # Unit tests (centralized, January 14 cleanup)
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”œâ”€â”€ conftest.py # Pytest configuration
â”‚ â”œâ”€â”€ run_tests.py # Run all tests
â”‚ â”œâ”€â”€ test_config.py # Config loader tests
â”‚ â”œâ”€â”€ test_encoder.py # Encoder shape tests
â”‚ â”œâ”€â”€ test_decoder.py # Decoder shape tests
â”‚ â”œâ”€â”€ test_losses.py # Loss computation tests
â”‚ â”œâ”€â”€ test_augmentation.py # Augmentation tests
â”‚ â”œâ”€â”€ test_smoke.py # Quick smoke tests
â”‚ â”œâ”€â”€ test_integration.py # End-to-end tests
â”‚ â”œâ”€â”€ test_phase0_data_pipeline.py # Data pipeline tests (moved from root)
â”‚ â”œâ”€â”€ test_training_single_batch.py # Single batch training test (moved from root)
â”‚ â””â”€â”€ test_mimic_clinical_extractor.py # MIMIC extraction tests (moved from root)
â”‚
â”œâ”€â”€ notebooks/ # Jupyter exploration (read-only reference)
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_signal_quality_analysis.ipynb
â”‚ â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚ â”œâ”€â”€ 04_clinical_data_integration.ipynb
â”‚ â”œâ”€â”€ 05_ssl_data_preparation.ipynb
â”‚â”‚    05_ssl_pretraining_colab.ipynb
â”‚ â”œâ”€â”€ 06_model_training.ipynb
â”‚ â”œâ”€â”€ 07_model_evaluation.ipynb
â”‚ â””â”€â”€ 08_interpretability.ipynb
â”‚
â”œâ”€â”€ logs/ # Training logs (Colab)
â”‚ â”œâ”€â”€ ssl/ # Phase 5 training logs
â”‚ â”‚ â”œâ”€â”€ training_history.json # Loss curves, metrics
â”‚ â”‚ â””â”€â”€ training.log # Stdout/stderr
â”‚ â””â”€â”€ mlruns/ # MLflow experiment tracking
â”‚
â”œâ”€â”€ exports/ # Final artifacts for deployment
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ encoder_best.onnx # Phase 5: Exported encoder
â”‚ â”‚ â””â”€â”€ vitaldb_results.json # Phase 8: Transfer learning results
â”‚ â”‚
â”‚ â”œâ”€â”€ feature_definitions/
â”‚ â”‚ â”œâ”€â”€ ssl_latent_dimensions.yaml # 512 learned features
â”‚ â”‚ â””â”€â”€ classical_features.yaml # HRV + morphology + context
â”‚ â”‚
â”‚ â””â”€â”€ metadata/
â”‚ â”œâ”€â”€ feature_statistics.json # Mean, std, min, max per feature
â”‚ â”œâ”€â”€ model_card.md # Model documentation
â”‚ â””â”€â”€ training_config.yaml # Hyperparameters used
â”‚
â”œâ”€â”€ context/ # Documentation & tracking (Updated January 20, 2026)
â”‚ â”œâ”€â”€ CLEANUP_SUMMARY.md # Documentation cleanup log
â”‚ â””â”€â”€ (Context folder for internal reference - content merged into docs/)
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Git ignore patterns
â”œâ”€â”€ README.md # Project overview
â””â”€â”€ setup.py # Package installation
```

---

## Module Descriptions by Phase

### **Phase 0: Data Preparation** âœ… Complete

- **mimic_ingestion.py**: Download 4,417 PPG signals from MIMIC-III
- **signal_preprocessing.py**: Filter + denoise â†’ 4,417 clean signals
- **dataset_assembly.py**: Create parquet metadata index

### **Phase 5A: Architecture Refactoring** âœ… Complete (Verified January 20)

- **encoder.py**: âœ… 3 blocks, accepts [B,1,1250] input, outputs [B,512]
- **decoder.py**: âœ… Mirror architecture, outputs [B,1,1250]
- **augmentation.py**: âœ… Window-aware (temporal_shift_range=0.02)
- **generate_mimic_windows.py**: âœ… Generated 653,716 overlapping windows
- **dataloader.py**: âœ… Window-based loading with SQI filtering
- **train.py**: âœ… CLI with auto-device detection
- **configs/ssl_pretraining.yaml**: âœ… Updated (batch_size=128, fft_pad_size=2048)

### **Phase 5B: Full Pretraining** â³ In Progress (Started January 20)

- **trainer.py**: Executing 50 epochs on 653,716 samples
- **losses.py**: âœ… Hybrid loss with optimized FFT padding (2048)
- **checkpoint_manager.py**: Auto-resume on timeout
- **Expected Timeline**: 50-90 minutes on T4 GPU
- **Success Criteria**: Val loss plateaus, train loss shows 55%+ reduction

### **Phase 6: Validation** â¬ Planned

- **reconstruction_metrics.py**: SSIM, MSE, correlation (target: >0.85, <0.005)
- **embedding_analysis.py**: Variance checks, PCA visualization

### **Phase 7: Feature Extraction** â¬ Planned

- **dataloader.py**: Batch load embeddings
- **feature_combiner.py**: Combine SSL + classical features
- **Output**: [4,417 Ã— 546] feature matrix

### **Phase 8: Transfer Learning** â¬ Planned

- **vitaldb_transfer.py**: âœ… **Critical fix #3 implemented**: Split by subject_id (STRING), not windows
- **transfer_learning_eval.py**: Compute AUROC per condition
- **report_generator.py**: Markdown report with interpretation

---

## Critical Fixes Applied (January 14, 2026)

### âœ… Fix #1: Data Leakage Prevention

**File**: `vitaldb_transfer.py` (Phase 8)  
**Change**: Split by subject (caseid) before assigning windows to train/test  
**Impact**: Honest cross-subject evaluation, no artificial AUROC inflation

### âœ… Fix #2: FFT Padding Efficiency

**File**: `configs/ssl_pretraining.yaml`  
**Change**: `fft_pad_size: 2048` (was 131,072)  
**Impact**: 67Ã— faster loss computation, eliminate 99% zero-padding waste

### âœ… Fix #3: Batch Size Optimization

**File**: `configs/ssl_pretraining.yaml`  
**Change**: `batch_size: 128`, `accumulation_steps: 1` (were 8, 4)  
**Impact**: 10Ã— faster epoch (1.5 min vs 16 min on T4)

---

## Key Dependencies

| Package          | Version | Purpose                                 |
| ---------------- | ------- | --------------------------------------- |
| **PyTorch**      | 2.1+    | Deep learning framework                 |
| **NumPy**        | 1.24+   | Numerical computing                     |
| **Pandas**       | 2.0+    | Data manipulation                       |
| **SciPy**        | 1.10+   | Signal processing (Chebyshev-II filter) |
| **scikit-learn** | 1.3+    | Logistic regression, train_test_split   |
| **PyWavelets**   | 1.4+    | Wavelet denoising (db4)                 |
| **NeuroKit2**    | 0.2.7+  | HRV feature extraction                  |
| **Matplotlib**   | 3.7+    | Visualization                           |

---

## Execution Environment

- **Local**: Python 3.10+, CPU for Phase 5A refactoring (4-5 hours)
- **Colab**: T4 GPU, 12GB+ RAM for Phases 5B-8 (12-18 hours actual GPU)
- **Reproducibility**: torch.manual_seed(42), deterministic=True

---

## Data Flow Summary

```
Phase 0: 4,417 MIMIC signals (75k samples each)
    â†“ [filter, denoise, quality check]
Phase 1-4: Codebase validation (existing)
    â†“ [generate overlapping windows]
Phase 5A: âœ… 653,716 overlapping 1,250-sample windows (generated, verified)
    â†“ [train encoder 50 epochs]
Phase 5B: â³ Trained encoder (best_encoder.pt) - IN PROGRESS
    â†“ [extract latent vectors]
Phase 6: Reconstruction validation (SSIM >0.85, MSE <0.005)
    â†“ [aggregate & combine with classical features]
Phase 7: 4,417 Ã— 546 feature matrix (512 SSL + 28 HRV + 6 morphology)
    â†“ [frozen encoder + VitalDB labels]
Phase 8: Cross-subject AUROC per condition (Hypertension/Diabetes/Obesity)
    â†“ [report & interpretation]
Final: Model documentation & deployment artifacts
```

---

**Status**: â³ Phase 5B In Execution (Started Jan 20, 2026)  
**Last Updated**: January 20, 2026  
**All Critical Fixes Applied & Verified**: Yes  
**Documentation Cleaned**: 14 obsolete .md files removed (Jan 20)
