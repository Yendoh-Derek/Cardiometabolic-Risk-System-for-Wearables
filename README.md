# Cardiometabolic Risk from PPG Signals

## Completion Status

- Phase 0â€“3: âœ… COMPLETE (Data prep + SSL modules + pilot training)
- Phase 4: âœ… COMPLETE (Colab deployment setup)
- Phase 5â€“8: ðŸš€ READY (Colab GPU training â†’ production API)

### Phase 0-3 Outputs

- **Data**: 4,417 PPG signals (train: 4,133, val: 200, test: 84)
- **SSL Modules**: 9 production-ready modules (encoder, decoder, losses, augmentation, trainer)
- **Tests**: 39 passing, 0 failures
- **Validation**: Pilot training 1 epoch, loss 6.88â†’2.06 (70% convergence âœ“)

### Phase 4 Deliverables

- **Validation Script**: `validate_phase4.py` â€” Quick module checks (<5 seconds)
- **Colab Notebook**: `notebooks/05_ssl_pretraining_colab.ipynb` â€” Single-page orchestration
- **Utils Helper**: `colab_src/utils/colab_utils.py` â€” Optional Colab detection
- **Documentation**: Updated README with Phase 5-8 roadmap

### Phase 5-8 Roadmap

| Phase | Goal                                  | Duration | Gate                                        |
| ----- | ------------------------------------- | -------- | ------------------------------------------- |
| **5** | Full 50-epoch training on Colab T4    | 8â€“12h    | Val loss <0.01, SSIM >0.80                  |
| **6** | Linear probe evaluation               | 1â€“2h     | AUROC >0.65 on â‰¥1 cardiometabolic condition |
| **7** | Extract embeddings + crafted features | 30min    | 551-dim feature matrix ready                |
| **8** | XGBoost downstream models             | 2â€“3h     | AUROC â‰¥0.70 on â‰¥2 conditions                |

---

## Quick Start

### Local Development

```bash
# Clone repository
git clone https://github.com/YOUR_ORG/cardiometabolic-risk-colab
cd cardiometabolic-risk-colab

# Install dependencies
pip install -r requirements.txt

# Run Phase 4 validation (quick check, <5 seconds)
python validate_phase4.py
```

### Colab Training

1. Open [Colab Notebook](notebooks/05_ssl_pretraining_colab.ipynb)
2. Run cells in order:
   - Mount Google Drive
   - Clone repository
   - Install dependencies
   - Verify GPU
   - Train (50 epochs, ~8-12 hours)
3. Download checkpoints from Drive

---

## Project Structure

```
cardiometabolic-risk-colab/
â”œâ”€â”€ colab_src/
â”‚   â”œâ”€â”€ models/ssl/              # SSL modules (Phase 1)
â”‚   â”‚   â”œâ”€â”€ config.py            # YAML config loader
â”‚   â”‚   â”œâ”€â”€ encoder.py           # ResNet encoder (2.8M params)
â”‚   â”‚   â”œâ”€â”€ decoder.py           # ResNet decoder (1.2M params)
â”‚   â”‚   â”œâ”€â”€ losses.py            # Multi-loss (MSE+SSIM+FFT)
â”‚   â”‚   â”œâ”€â”€ augmentation.py      # Label-free augmentations
â”‚   â”‚   â”œâ”€â”€ dataloader.py        # Lazy-loading dataset
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Training loop with grad accumulation
â”‚   â”‚   â”œâ”€â”€ train.py             # CLI entry point
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ colab_utils.py       # Colab helper functions
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ ssl_pretraining.yaml     # Full config (model, loss, training)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # MIMIC CSV files
â”‚   â”œâ”€â”€ processed/               # Parquets + denoised signals
â”‚   â”œâ”€â”€ cache/                   # Cached metadata
â”‚   â””â”€â”€ metadata/                # Dataset statistics
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_signal_quality_analysis.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 04_clinical_data_integration.ipynb
â”‚   â””â”€â”€ 05_ssl_pretraining_colab.ipynb   # Phase 5 entry point
â”œâ”€â”€ checkpoints/                 # Model checkpoints
â”‚   â”œâ”€â”€ phase3/                  # Phase 3 pilot checkpoint
â”‚   â””â”€â”€ phase5/                  # Phase 5 full training (will be created)
â”œâ”€â”€ logs/                        # MLflow logs
â”œâ”€â”€ tests/                       # 39 passing tests
â”œâ”€â”€ context/                     # Technical documentation
â”œâ”€â”€ validate_phase4.py           # Phase 4 validation script
â”œâ”€â”€ requirements.txt             # Locked dependencies
â””â”€â”€ README.md
```

---

## Architecture Overview

### Model

- **Encoder**: 1D ResNet, 75Kâ†’512-dim latent, 2.8M params
- **Decoder**: Transposed ResNet, 512â†’75K, 1.2M params
- **Total**: 4.0M parameters

### Loss Function

$$L_{total} = 0.50 \cdot L_{MSE} + 0.30 \cdot L_{SSIM} + 0.20 \cdot L_{FFT}$$

- **MSE**: Pixel-level temporal reconstruction
- **SSIM**: Structural similarity (morphology preservation)
- **FFT**: Frequency domain alignment (heart rate preservation)

### Training

- **Batch size**: 8 (with 4Ã— gradient accumulation = effective 32)
- **Optimizer**: Adam, LR=0.001
- **Mixed precision**: FP16 forward/backward, FP32 optimizer
- **Epochs**: 50
- **Data**: 4,133 training signals (10 min each @ 125 Hz)

---

## Documentation

- **Architecture**: [context/architecture.md](context/architecture.md) â€” System design, MIMIC integration
- **Phase 1 Implementation**: [context/phase_1_implementation.md](context/phase_1_implementation.md) â€” Technical specs
- **Phase 1 Checklist**: [context/phase_1_checklist.md](context/phase_1_checklist.md) â€” Verification tests
- **Phase 1 Review**: [context/PHASE_1_REVIEW.md](context/PHASE_1_REVIEW.md) â€” Code quality, performance analysis
- **Phase 0 Review**: [PHASE0_IMPLEMENTATION_REVIEW.md](PHASE0_IMPLEMENTATION_REVIEW.md) â€” Data pipeline design
- **Implementation Index**: [IMPLEMENTATION_INDEX.md](IMPLEMENTATION_INDEX.md) â€” Complete file reference

---

## Performance Predictions

### Phase 5: Full Training (50 epochs)

- **Hardware**: Colab T4 GPU (16GB VRAM)
- **Duration**: 8â€“12 hours (â‰ˆ10 min/epoch)
- **Memory**: Peak ~4â€“5 GB
- **Expected losses**:
  - MSE: 0.005â€“0.01 (pixel-level error)
  - SSIM: 0.80â€“0.90 (structural similarity)
  - Total: 0.01â€“0.02

### Phase 6: Linear Probe

- **Validation samples**: 24 (holdout test set)
- **Expected AUROC**: >0.65 on â‰¥1 cardiometabolic condition (gate)

### Phase 8: XGBoost Downstream

- **Training samples**: 60 (labeled test set)
- **Expected AUROC**: â‰¥0.70 on â‰¥2 conditions
- **Features**: 551-dim (512 latent + 39 crafted)

---

## Next Steps

1. **Phase 5**: Run full training in Colab

   - Expected: 8â€“12 hours on T4
   - Output: `best_encoder.pt` checkpoint

2. **Phase 6**: Linear probe evaluation

   - Quick validation of learned representations
   - Gate: AUROC >0.65

3. **Phase 7**: Embeddings + features

   - Extract 512-dim latent vectors for all 4,417 samples
   - Combine with 39 hand-crafted features

4. **Phase 8**: XGBoost models
   - Train 4 downstream classifiers (diabetes, hypertension, obesity, CCI)
   - Evaluate on 24-sample test set
   - Export as pickle + ONNX for production API

---

## Citation

If you use this codebase, please cite:

```bibtex
@dataset{cardiometabolic_ppg_2026,
  title={Self-Supervised Learning for Cardiometabolic Risk from PPG Signals},
  author={Your Name},
  year={2026},
  note={Based on MIMIC-III Matched Subset}
}
```

---

## License

MIT License â€” See LICENSE file

---

## Questions?

See [context/](context/) directory for detailed technical documentation.
